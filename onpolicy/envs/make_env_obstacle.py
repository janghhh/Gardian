# from MARL_test import ParallelEnv
import gym
import numpy as np
import airsim
import math
import time
import random
from sklearn.cluster import DBSCAN

# import open3d as o3d
# from sklearn.datasets import

class AirSimMultiDroneEnv:
    metadata = {"render_modes": []}

    def __init__(
        self,
        ip_address="127.0.0.1",                 # ê¸°ë³¸ê°’
        follower_names=("Follower0","Follower1","Follower2"),
        lidar_name="LidarSensor",               # ë¼ì´ë‹¤ ê³µí†µëª… (ì‹¤ì œ ì„¼ì„œëŠ” f"{agent}_{lidar_name}")
        min_samples=5,
        step_length=1.0,
        fixed_z=-10.0,
        leader_velocity=0.0,                    # ìœ ì¸ê¸° ì†ë„(m/s) íŒŒë¼ë¯¸í„°í™”
        optimal_distance=10.0,                  # ì¶”ì¢… ìµœì  ê±°ë¦¬(ì‹œê°í™”ìš© ë§)
        far_cutoff=60.0,                        # ì´íƒˆ ì¢…ë£Œ ê±°ë¦¬(ì‹œê°í™”ìš© ë§)
        too_close=0.5,                          # ìœ ì¸ê¸°ì™€ ìµœì†Œ ê±°ë¦¬
        dt=0.05,                                # ë‚´ë¶€ ì‹œë®¬ë ˆì´ì…˜ íƒ€ì„ìŠ¤í…(ì´ˆ)
        do_visualize=True                       # ì›/í¬ì¸íŠ¸ ì‹œê°í™” on/off
    ):
        super().__init__()
        self.possible_agents = list(follower_names)
        self.agents = self.possible_agents[:]

        # ë¼ì´ë‹¤ / DBSCAN
        self.lidar_name = lidar_name
        self.min_samples = int(min_samples)
        self.eps = 0.3
        self.min_pts = 5

        # ê´€ì¸¡ê³µê°„(ë™ì  ê°ì²´ K-NN)
        self.K_nearest = 4                  # K-ìµœê·¼ì ‘ ë™ì  ê°ì²´ ê°œìˆ˜
        self.match_dist_max = 2.0           # í”„ë ˆì„ ê°„ í´ëŸ¬ìŠ¤í„° ë§¤ì¹­ í—ˆìš© ê±°ë¦¬[m]
        self._cluster_tracks = {a: {} for a in self.possible_agents}  # agentë³„ íŠ¸ë™ ì‚¬ì „
        self._next_cluster_id = {a: 0 for a in self.possible_agents}  # agentë³„ ID ì¦ê°€ê¸°

        # ì—ì´ì „íŠ¸/ë¦¬ë” ì†ë„ ì‚°ì¶œìš© ë²„í¼
        self._last_pose = {}     # {"name": np.array([x,y,z])}
        self._last_time = {}     # {"name": t_float}

        # ì†ë„/ì•¡ì…˜ ë²„í¼
        self.vmax_self = 10.0             # ìê¸° ì†ë„ ìƒí•œ(m/s) (í•™ìŠµ ì•ˆì •ìš©)
        self.vmax_cluster = 15.0
        self._timestep = 0

        # KeyError ë°©ì§€: ì•¡ì…˜ ë²„í¼ë¥¼ ì—ì´ì „íŠ¸ë³„ë¡œ ì´ˆê¸°í™”
        self._last_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self._current_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self.success_steps = {a: 0 for a in self.possible_agents}

        # ì´ë™ ëª¨ë“œ
        self.use_teleport = True  # Trueë©´ ìœ„ì¹˜ ë³´ì •(í…”ë ˆí¬íŠ¸) ê¸°ë°˜ ì´ë™

        # í´ë¼ì´ì–¸íŠ¸
        self.client = airsim.MultirotorClient(ip=ip_address)
        self.client.confirmConnection()

        # í•˜ì´í¼íŒŒë¼ë¯¸í„°/í™˜ê²½ íŒŒë¼ë¯¸í„°
        self.step_length = float(step_length)
        self.fixed_z = float(fixed_z)
        self.dt = float(dt)
        self.do_visualize = bool(do_visualize)

        self.leader_velocity = float(leader_velocity)
        self.optimal_distance = float(optimal_distance)
        self.far_cutoff = float(far_cutoff)
        self.too_close = float(too_close)
        self.follower_names = list(follower_names)

        self._first_setup = True
        self.leader_stop = False

        # ===== obs / act / share_obs spaces =====
        # obs_dim = [self_vel(3) + rel_leader(3) + K * (rel_pos(3)+rel_vel(3))]
        obs_dim = 3 + 3 + self.K_nearest * (3 + 3)   # = 30
        act_dim = 2
        share_obs_dim = obs_dim * len(self.possible_agents)

        low_self = [-20.0, -20.0, -20.0]             # ì†ë„/ìƒëŒ€ìœ„ì¹˜ ëŒ€ëµì  í´ë¦½
        high_self = [ 20.0,  20.0,  20.0]
        low_rel = [-200.0, -200.0, -200.0]
        high_rel = [ 200.0,  200.0,  200.0]
        low_kn = [-200.0]*3 + [-20.0]*3
        high_kn = [ 200.0]*3 + [ 20.0]*3
        per_agent_low  = low_self + low_rel + (low_kn * self.K_nearest)
        per_agent_high = high_self + high_rel + (high_kn * self.K_nearest)

        self.observation_spaces = {
            agent: gym.spaces.Box(
                low=np.array(per_agent_low,  dtype=np.float32),
                high=np.array(per_agent_high, dtype=np.float32),
                shape=(obs_dim,), dtype=np.float32
            ) for agent in self.possible_agents
        }

        self.action_spaces = {
            agent: gym.spaces.Box(low=-1.0, high=1.0, shape=(act_dim,), dtype=np.float32)
            for agent in self.possible_agents
        }

        self.share_observation_spaces = gym.spaces.Box(
            low=np.array(per_agent_low * len(self.possible_agents), dtype=np.float32),
            high=np.array(per_agent_high * len(self.possible_agents), dtype=np.float32),
            shape=(share_obs_dim,), dtype=np.float32
        )

        self.current_waypoint_idx = 0
        self.dynamic_name = "DynamicObstacle"
        self._setup_flight()
        self._last_visualize_t = time.time()

    # ======================================================================
    # ë¼ì´ë‹¤ ë°ì´í„° â†’ DBSCAN â†’ íŠ¸ë™/ì†ë„ ì¶”ì •
    # ======================================================================
    def _lidar_sensor_name(self, agent: str) -> str:
        # ì‹¤ì œ AirSim ì„¤ì •: ê° ë“œë¡ ì— "Follower0_LidarSensor" ì‹ìœ¼ë¡œ ë¶™ì–´ ìˆë‹¤ê³  ê°€ì •
        return f"{agent}_{self.lidar_name}"

    def _LidarPointsWorld(self, agent, data_frame="VehicleInertialFrame"):
        ld = self.client.getLidarData(lidar_name=self._lidar_sensor_name(agent), vehicle_name=agent)
        arr = np.array(ld.point_cloud, dtype=np.float32)
        if arr.size == 0:
            return np.empty((0, 3), dtype=np.float32)
        pts = arr.reshape(-1, 3)
        return pts

    def _ClusterDbscanWorld(self, agent):
        pts_w = self._LidarPointsWorld(agent, data_frame="VehicleInertialFrame")
        if pts_w.shape[0] == 0:
            return []
        db = DBSCAN(eps=self.eps, min_samples=self.min_samples).fit(pts_w)
        labels = db.labels_
        clusters = []
        for cid in np.unique(labels):
            if cid == -1:
                continue
            idx = (labels == cid)
            cpts = pts_w[idx]
            centroid = cpts.mean(axis=0)
            clusters.append({"centroid": centroid, "count": int(idx.sum())})
        return clusters

    def _update_clusters_and_tracks(self, agent, now_t):
        tracks = self._cluster_tracks[agent]
        clusters = self._ClusterDbscanWorld(agent)

        cur_centroids = [c["centroid"] for c in clusters]
        cur_used = [False] * len(cur_centroids)

        # ê¸°ì¡´ íŠ¸ë™ ì—…ë°ì´íŠ¸/ì‚­ì œ
        for tid, st in list(tracks.items()):
            best_j, best_d = -1, 1e9
            for j, cen in enumerate(cur_centroids):
                if cur_used[j]:
                    continue
                d = np.linalg.norm(cen - st["centroid"])
                if d < best_d:
                    best_d, best_j = d, j

            if best_j >= 0 and best_d <= self.match_dist_max:
                dt = max(1e-6, now_t - st["last_t"])
                new_c = cur_centroids[best_j]
                vel = (new_c - st["centroid"]) / dt
                # í´ë¨í”„ + EMA
                vel = np.clip(vel, -self.vmax_cluster, self.vmax_cluster)
                prev = st.get("vel", np.zeros(3, np.float32))
                vel = 0.6 * prev + 0.4 * vel
                tracks[tid] = {"centroid": new_c, "vel": vel, "last_t": now_t}
                cur_used[best_j] = True
            else:
                if now_t - st["last_t"] > 1.0:
                    del tracks[tid]

        # ë§¤ì¹­ ì•ˆ ëœ í´ëŸ¬ìŠ¤í„°ëŠ” ì‹ ê·œ íŠ¸ë™ ìƒì„±
        for j, cen in enumerate(cur_centroids):
            if not cur_used[j]:
                tid = self._next_cluster_id[agent]
                self._next_cluster_id[agent] += 1
                tracks[tid] = {"centroid": cen, "vel": np.zeros(3, np.float32), "last_t": now_t}

    # ======================================================================
    # í¬ì¦ˆ/ì†ë„
    # ======================================================================
    def _get_pose_xyz(self, name):
        pose = self.client.simGetVehiclePose(vehicle_name=name).position
        return np.array([pose.x_val, pose.y_val, pose.z_val], dtype=np.float32)

    def _get_self_velocity(self, name, now_t, current_pos):
        """
        [ìµœì í™”ë¨] _get_pose_xyz() API í˜¸ì¶œì„ ì œê±°í•˜ê³ ,
        ë¯¸ë¦¬ ê³„ì‚°ëœ current_posë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        """
        if self.use_teleport and name in self._last_action:
            # í…”ë ˆí¬íŠ¸ ëª¨ë“œ (ê¸°ì¡´ê³¼ ë™ì¼, API í˜¸ì¶œ ì—†ìŒ)
            a = self._last_action[name] 
            vx = float(a[0]) * float(self.step_length) / self.dt
            vy = float(a[1]) * float(self.step_length) / self.dt
            vz = 0.0
            v = np.array([vx, vy, vz], dtype=np.float32)
        else:
            # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ì¸ìë¡œ ë°›ì€ 'current_pos' ì‚¬ìš©
            pos = current_pos 
            v = np.zeros(3, np.float32)
            if name in self._last_pose:
                dt = max(1e-6, now_t - self._last_time.get(name, now_t))
                v = (pos - self._last_pose[name]) / dt
            self._last_pose[name] = pos
            self._last_time[name] = now_t

        # í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•œ í´ë¨í”„ & EMA (ê¸°ì¡´ê³¼ ë™ì¼)
        v = np.clip(v, -self.vmax_self, self.vmax_self)
        prev = getattr(self, "_vel_ema_" + name, v)
        v_ema = 0.7 * prev + 0.3 * v
        setattr(self, "_vel_ema_" + name, v_ema)
        return v_ema

    def _get_knn_features(self, agent, K, now_t, all_poses):
        """
        _get_pose_xyz() API í˜¸ì¶œì„ ì œê±°í•˜ê³ ,
        ë¯¸ë¦¬ ê³„ì‚°ëœ all_poses ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©
        """
        
        # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ
        pos_a = all_poses[agent]
        
        # (ìˆ˜ì •) ìµœì í™”ëœ ì†ë„ í•¨ìˆ˜ í˜¸ì¶œ
        vel_a = self._get_self_velocity(agent, now_t, pos_a)

        feats = []
        cand = []
        # (ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
        for _, tr in self._cluster_tracks[agent].items():
            rel_pos = tr["centroid"] - pos_a
            rel_vel = tr["vel"] - vel_a
            dist = np.linalg.norm(rel_pos)
            cand.append((dist, rel_pos, rel_vel))
        cand.sort(key=lambda x: x[0])

        for i in range(K):
            if i < len(cand):
                _, rp, rv = cand[i]
                feats.extend([rp[0], rp[1], rp[2], rv[0], rv[1], rv[2]])
            else:
                feats.extend([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # íŒ¨ë”©
        return np.array(feats, dtype=np.float32)

    # ======================================================================
    # Spaces (PettingZoo-style getters)
    # ======================================================================
    # def _get_lidar_obs(self, agent, lidar_name="LidarSensor1"):
    #     lidar_data = self.client.getLidarData(vehicle_name=agent, lidar_name=lidar_name)
    #     if len(lidar_data.point_cloud) < 3:
    #         return np.full(36, self.far_cutoff, dtype=np.float32)

    #     pts = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)
    #     dists = np.linalg.norm(pts[:, :2], axis=1)
    #     angles = np.arctan2(pts[:, 1], pts[:, 0])

    #     bins = np.linspace(-math.pi, math.pi, 37)
    #     min_dists = np.full(36, self.far_cutoff, dtype=np.float32)

    #     for i in range(36):
    #         sel = dists[(angles >= bins[i]) & (angles < bins[i+1])]
    #         if len(sel) > 0:
    #             min_dists[i] = np.min(sel)
    #     return min_dists
    
    def _get_lidar_obs(self, agent):
        lidar_data = self.client.getLidarData(
            vehicle_name=agent,
            lidar_name=self._lidar_sensor_name(agent)
        )
        if len(lidar_data.point_cloud) < 3:
            return np.full(36, self.far_cutoff, dtype=np.float32)

        pts = np.array(lidar_data.point_cloud, dtype=np.float32).reshape(-1, 3)
        dists = np.linalg.norm(pts[:, :2], axis=1)
        angles = np.arctan2(pts[:, 1], pts[:, 0])

        bins = np.linspace(-math.pi, math.pi, 37)
        min_dists = np.full(36, self.far_cutoff, dtype=np.float32)

        for i in range(36):
            sel = dists[(angles >= bins[i]) & (angles < bins[i+1])]
            if len(sel) > 0:
                min_dists[i] = np.min(sel)
        return min_dists


    @property
    def observation_space(self):
        return [self.observation_spaces[a] for a in self.possible_agents]

    @property
    def action_space(self):
        return [self.action_spaces[a] for a in self.possible_agents]

    @property
    def share_observation_space(self):
        return [self.share_observation_spaces for _ in self.possible_agents]

    def seed(self, seed):
        random.seed(seed)
        np.random.seed(seed)

    # ======================================================================
    # ì´ˆê¸°í™”/ì´ë¥™/ì‹œì‘ ë°°ì¹˜
    # ======================================================================
    def _setup_flight(self):
        if self._first_setup:
            self.client.reset()
            self.client.enableApiControl(True, vehicle_name="Drone1")
            self.client.armDisarm(True, vehicle_name="Drone1")
            for agent in self.possible_agents:
                self.client.enableApiControl(True, vehicle_name=agent)
                self.client.armDisarm(True, vehicle_name=agent)

            # âœ… ë™ì ì¥ì• ë¬¼ ì œì–´ ì¶”ê°€
            self.client.enableApiControl(True, vehicle_name=self.dynamic_name)
            self.client.armDisarm(True, vehicle_name=self.dynamic_name)

            futs = [self.client.takeoffAsync(vehicle_name="Drone1")]
            futs += [self.client.takeoffAsync(vehicle_name=a) for a in self.possible_agents]
            futs += [self.client.takeoffAsync(vehicle_name=self.dynamic_name)]
            for f in futs: f.join()

            time.sleep(1.0)
            self._teleport_to_start()
            self._first_setup = False

    def _teleport_to_start(self):
        leader_start_x, leader_start_y = 5.0, 2.5
        self.leader_home_pose = airsim.Pose(
            airsim.Vector3r(float(leader_start_x), float(leader_start_y), float(self.fixed_z)),
            airsim.Quaternionr(0.0, 0.0, 0.0, 1.0)
        )
        radius = random.uniform(20.0, 40.0) 
        angle = random.uniform(0, 2 * np.pi)
        obstacle_start_x = leader_start_x + radius * np.cos(angle)
        obstacle_start_y = leader_start_y + radius * np.sin(angle)
        # settings.jsonì— ë§ì¶˜ ì‹œì‘ ì¢Œí‘œ (X, Y, Z)
        start_cfg = {
            "Drone1":   (5.0,  2.5, self.fixed_z),
            "Follower0":(0.0,  0.0, self.fixed_z),
            "Follower1":(0.0,  2.5, self.fixed_z),
            "Follower2":(0.0,  5.0, self.fixed_z),
            # ë™ì ì¥ì• ë¬¼ ì‹œì‘ ìœ„ì¹˜
            self.dynamic_name: (obstacle_start_x, obstacle_start_y, self.fixed_z),
        }
        # API ì œì–´ ë³´ì¥
        self.client.enableApiControl(True, vehicle_name="Drone1")
        for agent in self.possible_agents:
            self.client.enableApiControl(True, vehicle_name=agent)
        # í…”ë ˆí¬íŠ¸
        for name, (x, y, z) in start_cfg.items():
            px, py, pz = float(x), float(y), float(z)
            self.client.simSetVehiclePose(
                airsim.Pose(
                    airsim.Vector3r(px, py, pz),
                    airsim.Quaternionr(0.0, 0.0, 0.0, 1.0)
                ),
                ignore_collision=True,
                vehicle_name=name
            )
        time.sleep(0.05)


    def _update_leader_movement(self):
        """
        ìœ ì¸ê¸°ë¥¼ í˜„ì¬ X,Y ìœ„ì¹˜ì˜ self.fixed_zì— "ê³ ì •" (ì¶”ë½ ë°©ì§€).
        ì‹œê°í™” ë‹´ë‹¹.
        """
        # --- [ì¶”ê°€] ì¶”ë½ ë°©ì§€ë¥¼ ìœ„í•œ ìœ„ì¹˜ ê³ ì • ---
        try:
            # (ìˆ˜ì •) í˜„ì¬ ìœ„ì¹˜(Get)ë¥¼ ì½ì§€ ì•Šê³ , ì €ì¥ëœ 'í™ˆ' ìœ„ì¹˜(Set)ë¥¼ ê°•ì œ ì ìš©
            self.client.simSetVehiclePose(
                self.leader_home_pose, # (5.0, 2.5, self.fixed_z)
                ignore_collision=True,
                vehicle_name="Drone1"
            )
        except Exception as e:
            # ì‹œë®¬ë ˆì´ì…˜ ì—°ê²°ì´ ëŠê²¼ì„ ë•Œë¥¼ ëŒ€ë¹„í•œ ì˜ˆì™¸ ì²˜ë¦¬
            print(f"Leader(Drone1) ìœ„ì¹˜ ê³ ì • ì¤‘ ì˜¤ë¥˜: {e}")
        # --- [ì¶”ê°€ ë] ---


        # ì‹œê°í™” (ìœ ì¸ê¸° ìœ„ì¹˜ëŠ” _visualize_circles ë‚´ë¶€ì—ì„œ ì§ì ‘ ì¡°íšŒ)
        if self.do_visualize:
            now = time.time()
            if (now - self._last_visualize_t) >= 0.1:
                self.client.simFlushPersistentMarkers()
                self._visualize_circles()
                self._last_visualize_t = now

        # ë¯¸ì…˜ ì„±ê³µ(True)ì„ ë°˜í™˜í•˜ì§€ ì•ŠìŒ
        return False

    # --------------------- ì‹œê°í™” ---------------------
    def _visualize_circles(self):
        try:
            leader_pos = self.client.simGetObjectPose("Drone1").position
            center = np.array([leader_pos.x_val, leader_pos.y_val, leader_pos.z_val], dtype=float)

            def ring_points(radius, n=36):
                pts = []
                for i in range(n+1):
                    ang = (i / n) * 2 * np.pi
                    x = center[0] + radius * np.cos(ang)
                    y = center[1] + radius * np.sin(ang)
                    z = center[2]
                    pts.append(airsim.Vector3r(x, y, z))
                return pts

            line_thickness = 20.0
            self.client.simPlotLineStrip(ring_points(self.optimal_distance), [1, 1, 0, 0.8], line_thickness, 0.15, True)
            self.client.simPlotLineStrip(ring_points(self.far_cutoff), [0, 1, 0, 0.8], line_thickness, 0.15, True)
        except Exception:
            pass


    # ======================================================================
    # ê´€ì¸¡/ì•¡ì…˜/ë³´ìƒ
    # ======================================================================
    def _get_obs(self, agent, now_t, all_poses):
        now_t = self._timestep * self.dt
        """
        API í˜¸ì¶œ ì—†ì´ all_poses ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ ê´€ì¸¡ê°’ì„ ìƒì„±
        """
    
        # 1) ìì‹  ì†ë„
        # (ìˆ˜ì •) _get_pose_xyzë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šë„ë¡, í˜„ì¬ ìœ„ì¹˜(all_poses[agent])ë¥¼ ì¸ìë¡œ ì „ë‹¬
        self_vel = self._get_self_velocity(agent, now_t, all_poses[agent])

        # 2) ìœ ì¸ê¸° ìƒëŒ€ ìœ„ì¹˜ (ë¦¬ë”-ì—ì´ì „íŠ¸)
        # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ
        leader_pos = all_poses["Drone1"]
        agent_pos  = all_poses[agent]
        rel_la = (leader_pos - agent_pos).astype(np.float32)

        # 3) K-ìµœê·¼ì ‘ ë™ì  ê°ì²´: ìƒëŒ€ ìœ„ì¹˜ + ìƒëŒ€ ì†ë„
        # (ìˆ˜ì •) _get_knn_featuresê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
        kn_feats = self._get_knn_features(agent, self.K_nearest, now_t, all_poses)

        obs = np.concatenate([self_vel, rel_la, kn_feats], axis=0).astype(np.float32)
        return obs

    def _do_action(self, agent, action):
        a = np.clip(np.asarray(action, dtype=np.float32), -1.0, 1.0)
        self._last_action[agent] = a.copy()
        self._current_action[agent] = a.copy()  # â˜… í˜„ì¬ ì•¡ì…˜ ê¸°ë¡ (KeyError ë°©ì§€)

        pose = self.client.simGetVehiclePose(agent)
        x, y, z = pose.position.x_val, pose.position.y_val, self.fixed_z

        dx = float(a[0]) * float(self.step_length)
        dy = float(a[1]) * float(self.step_length)

        nx = float(x) + dx
        ny = float(y) + dy
        nz = float(z)

        new_pos = airsim.Vector3r(nx, ny, nz)
        new_pose = airsim.Pose(new_pos, airsim.Quaternionr(0.0, 0.0, 0.0, 1.0))
        self.client.simSetVehiclePose(new_pose, False, vehicle_name=agent)
  
    # --------------------- ë³´ìƒ ---------------------
    def _compute_reward(self, agent, all_poses):
        agent_pos  = all_poses[agent]
        leader_pos = all_poses["Drone1"]

        # (1) ì—ì´ì „íŠ¸ ê°„ ì¶©ëŒ
        for other in self.agents:
            if other == agent:
                continue
            other_pos = all_poses[other]
            if np.linalg.norm(agent_pos[:2] - other_pos[:2]) < 0.5:
                return -150.0, True  # ì¶©ëŒ ì‹œ ì¢…ë£Œ

        # (2) ë¦¬ë”ì™€ì˜ ê±°ë¦¬ ê³„ì‚°
        rel = leader_pos - agent_pos
        dist = np.hypot(rel[0], rel[1])

        # ë„ˆë¬´ ê°€ê¹Œì›€ or ë„ˆë¬´ ë©€ë©´ ì¢…ë£Œ
        if dist < 0.5 or dist > 60.0:
            return -150.0, True

        # ê±°ë¦¬ ë³´ìƒ 
        if 5.0 <= dist <= 10.0:
            # ìµœì  ê±°ë¦¬ êµ¬ê°„: ìµœê³  ë³´ìƒ
            reward = 3.0
        elif 0.5 <= dist < 5.0:
            # 0.5~5m: ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ê¸‰ê° (-150 â†’ +3)
            reward = -150.0 + (153.0) * math.exp(-((dist - 5.0)**2) / (2 * 1.5**2))
        elif 10.0 < dist <= 60.0:
            # 10~60m: ë©€ì–´ì§ˆìˆ˜ë¡ ê°ì  (+3 â†’ -150)
            reward = -150.0 + (153.0) * math.exp(-((dist - 10.0)**2) / (2 * 15.0**2))
        else:
            reward = -150.0

        if self.leader_stop:
            return -150.0, True

        return float(reward), False

    # --------------------- íŒ€ ë³´ìƒ ì§‘ê³„ ---------------------
    # íŒ€ ë³´ìƒ ì§‘ê³„(í‰ê· ) + ì•ˆì „ ê²Œì´íŠ¸
    def _team_reward_and_done(self, per_agent_results, mission_accomplished=False):
        # ì•ˆì „ ê²Œì´íŠ¸: í•œ ëª…ì´ë¼ë„ ì¢…ë£Œì´ë©´ ì¦‰ì‹œ ì‹¤íŒ¨
        any_fail = any(done_i for (_, done_i) in per_agent_results)
        if any_fail:
            return -200.0, True, {"final_status": "FAIL_CRASH"}

        # ë¯¸ì…˜ ì„±ê³µ: ìœ ì¸ê¸°ê°€ í”¼ê²©ë‹¹í•˜ì§€ ì•ŠëŠ” ê²ƒ.
        if mission_accomplished:
            tracking_rewards = [r_i for (r_i, _) in per_agent_results]
            final_reward = float(np.mean(tracking_rewards)) + 500.0
            return final_reward, True, {"final_status": "SUCCESS"}

        # ë¯¸ì…˜ ì§„í–‰ ì¤‘: ì¶”ì¢… ë³´ìƒì˜ í‰ê· 
        tracking_rewards = [r_i for (r_i, _) in per_agent_results]
        return float(np.mean(tracking_rewards)), False, {}
    

    # --------------------- ë™ì ì¥ì• ë¬¼ FSM + ì§ì„ /ê³¡ì„  ì¶”ê²© ---------------------
    def _update_dynamic_obstacle(self, t):
        name = self.dynamic_name
        fixed_z = self.fixed_z
        attack_speed = 5.0
        STOP_DISTANCE = 1.0

        # ìƒíƒœ ë³€ìˆ˜ ì´ˆê¸°í™”
        if not hasattr(self, "_obstacle_state"):
            self._obstacle_state = "IDLE"
            self._next_chase_time = time.time() + random.uniform(1.0, 3.0)
            self._idle_pos = None
            self._chase_mode = None  # 'STRAIGHT' or 'CURVED'

        leader_pose = self.client.simGetObjectPose("Drone1").position
        obstacle_pose = self.client.simGetObjectPose(name).position
        lx, ly, lz = leader_pose.x_val, leader_pose.y_val, leader_pose.z_val
        cx, cy, cz = obstacle_pose.x_val, obstacle_pose.y_val, obstacle_pose.z_val

        dx, dy = lx - cx, ly - cy
        dist_2d = math.sqrt(dx**2 + dy**2) + 1e-9

        # ------------------ IDLE ëª¨ë“œ ------------------
        if self._obstacle_state == "IDLE":
            if self._idle_pos is None:
                radius = random.uniform(60.0, 70.0)
                angle = random.uniform(0, 2 * np.pi)
                self._idle_pos = (lx + radius * np.cos(angle), ly + radius * np.sin(angle))
                print(f"[ëŒ€ê¸°ëª¨ë“œ] {radius:.1f}m ê±°ë¦¬ì—ì„œ ëŒ€ê¸°")

            ix, iy = self._idle_pos
            dx_i, dy_i = ix - cx, iy - cy
            dist_idle = math.sqrt(dx_i**2 + dy_i**2)
            if dist_idle > 1.0:
                vx = dx_i / dist_idle * 2.0
                vy = dy_i / dist_idle * 2.0
                vz = (fixed_z - cz) * 0.3
                self.client.moveByVelocityAsync(vx, vy, vz, duration=0.1, vehicle_name=name)
            else:
                self.client.moveByVelocityAsync(0, 0, 0, duration=0.1, vehicle_name=name)

            # ì¼ì • ì‹œê°„ í›„ ì¶”ê²© ì‹œì‘
            if time.time() > self._next_chase_time:
                self._obstacle_state = "CHASE"
                self._chase_start = time.time()
                self._chase_mode = random.choice(["STRAIGHT", "CURVED"])
                print(f"[ì¶”ê²© ì‹œì‘] ëª¨ë“œ: {self._chase_mode}")
                return

        # ------------------ CHASE ëª¨ë“œ ------------------
        elif self._obstacle_state == "CHASE":
            elapsed = time.time() - self._chase_start
            chase_duration = random.uniform(15.0, 16.0)

            if elapsed > chase_duration:
                print(f"[ì¶”ê²© ì¢…ë£Œ] ({self._chase_mode}) {elapsed:.1f}s í›„ ëŒ€ê¸° ë³µê·€")
                self._obstacle_state = "RETURN"
                self._idle_pos = None
                self._next_chase_time = time.time() + random.uniform(1.0, 3.0)
                return

            if dist_2d <= STOP_DISTANCE:
                # print(f"[ì •ì§€] Drone1ê³¼ ê±°ì˜ ì¼ì¹˜ (ê±°ë¦¬={dist_2d:.2f}m)")
                vz = (fixed_z - cz )*8.0
                self.client.moveByVelocityAsync(0, 0, 0, duration=0.1, vehicle_name=name)
                self.leader_stop = True
                return

            # === [ìˆ˜ì •ëœ í•µì‹¬ ë¡œì§] ===
            # 'CURVED' ëª¨ë“œì¼ ë•Œ 5m ì´ë‚´ë¡œ ì ‘ê·¼í•˜ë©´, 'STRAIGHT' ëª¨ë“œë¡œ "ìƒíƒœë¥¼ ë³€ê²½"
            if self._chase_mode == "CURVED" and dist_2d < 5.0:
                print(f"[ê³¡ì„ ->ì§ì„ ] 2m ì´ë‚´({dist_2d:.1f}m), ì§ì„  ëŒê²© ëª¨ë“œë¡œ ë³€ê²½!")
                self._chase_mode = "STRAIGHT"
            # === [ìˆ˜ì • ë] ===


            dir_x = dx / dist_2d
            dir_y = dy / dist_2d
            
            # --- (1) ì§ì„  ì¶”ê²© ---
            # (ì´ì œ self._chase_modeê°€ 'STRAIGHT'ë¡œ ë°”ë€Œì—ˆê¸° ë•Œë¬¸ì— ì´ ë¡œì§ì´ ì‹¤í–‰ë¨)
            if self._chase_mode == "STRAIGHT":
                vx = dir_x * attack_speed
                vy = dir_y * attack_speed

            # --- (2) ê³¡ì„  ì¶”ê²© ---
            elif self._chase_mode == "CURVED": # (self._chase_mode == "CURVED" ì´ê³  ì•„ì§ 2m ë°–ì¼ ë•Œ)
                amplitude = 10.0
                freq = 1.0
                phase = math.sin(2.0 * math.pi * freq * t/2)
                perp_x = -dir_y
                perp_y = dir_x
                vx = (dir_x * attack_speed) + (perp_x * amplitude * phase)
                vy = (dir_y * attack_speed) + (perp_y * amplitude * phase)

            vz = (fixed_z - cz )*8.0
            self.client.moveByVelocityAsync(vx, vy, vz, duration=0.1, vehicle_name=name)


        # ------------------ RETURN ëª¨ë“œ ------------------
        elif self._obstacle_state == "RETURN":
            if self._idle_pos is None:
                radius = random.uniform(30.0, 50.0)
                angle = random.uniform(0, 2 * np.pi)
                self._idle_pos = (lx + radius * np.cos(angle), ly + radius * np.sin(angle))
                # print(f"[ëŒ€ê¸° ìœ„ì¹˜ ì¬ì„¤ì •] ìƒˆ ì§€ì ìœ¼ë¡œ ë³µê·€ ì¤‘")

            ix, iy = self._idle_pos
            dx_r, dy_r = ix - cx, iy - cy
            dist_return = math.sqrt(dx_r**2 + dy_r**2)
            if dist_return > 1.0:
                vx = dx_r / dist_return * 3.0
                vy = dy_r / dist_return * 3.0
                vz = (fixed_z - cz) * 8.0
                self.client.moveByVelocityAsync(vx, vy, vz, duration=0.1, vehicle_name=name)
            else:
                self._obstacle_state = "IDLE"
                self._next_chase_time = time.time() + random.uniform(1.0, 3.0)
                # print("[ëŒ€ê¸°ëª¨ë“œ ë³µê·€ ì™„ë£Œ]")




    # ======================================================================
    # PettingZoo API-ish
    # ======================================================================   
    def reset(self, seed=None, options=None):
        self.agents = self.possible_agents[:]
        self._setup_flight()
        self.current_waypoint_idx = 0
        self._teleport_to_start() # <- ë“œë¡  ìœ„ì¹˜ê°€ ì—¬ê¸°ì„œ ì„¤ì •ë¨
        self.client.enableApiControl(True, vehicle_name=self.dynamic_name)
        self.client.simFlushPersistentMarkers()

        # ì—í”¼ì†Œë“œ ì‹œì‘ ì‹œ ë²„í¼ ë¦¬ì…‹ 
        self._timestep = 0
        self._last_pose.clear()
        self._last_time.clear()
        self._last_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self._current_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self.success_steps = {a: 0 for a in self.possible_agents}
        self._cluster_tracks = {a: {} for a in self.possible_agents}
        self._next_cluster_id = {a: 0 for a in self.possible_agents}

        # 'step' í•¨ìˆ˜ì—ì„œì²˜ëŸ¼ 'now_t'ì™€ 'all_poses'ë¥¼ ìƒì„±
        # now_t = self._timestep * self.dt  # (now_t = 0.0)
        
        all_poses = {}
        all_poses["Drone1"] = self._get_pose_xyz("Drone1") # ìœ ì¸ê¸°
        for agent in self.agents:
            all_poses[agent] = self._get_pose_xyz(agent) # ì—ì´ì „íŠ¸

        now_t = 0.0
        obs_list = [self._get_obs(a, now_t, all_poses) for a in self.agents]

        self._obstacle_state = "IDLE"
        self._idle_pos = None
        self._next_chase_time = time.time() + random.uniform(1.0, 3.0)
        self._chase_mode = None
        self.leader_stop = False
        # print("[Reset] ë™ì ì¥ì• ë¬¼ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ")
        return obs_list
    

    def step(self, actions):
        self._timestep += 1
        t = time.time()  # í˜„ì¬ ì‹œê°„ ì €ì¥
        self._update_dynamic_obstacle(t)
        now_t = self._timestep * self.dt

        # A) LiDAR ê¸°ë°˜ íŠ¸ë™ ê°±ì‹ 
        for agent in self.agents:
            if agent.startswith("Follower"):
                self._update_clusters_and_tracks(agent, now_t)

        # B) ì•¡ì…˜ ì ìš©
        for agent, act in zip(self.agents, actions):
            self._do_action(agent, act)

        # C) ë¦¬ë” ì´ë™/ì‹œê°í™”
        self._update_leader_movement()
        mission_accomplished = False

        # ëª¨ë“  ìœ„ì¹˜ ì •ë³´ë¥¼ ì´ ì‹œì ì— "í•œ ë²ˆë§Œ" ê°€ì ¸ì˜´
        all_poses = {}
        all_poses["Drone1"] = self._get_pose_xyz("Drone1") # ìœ ì¸ê¸°
        for agent in self.agents:
            all_poses[agent] = self._get_pose_xyz(agent) # ì—ì´ì „íŠ¸

        # D) ê´€ì¸¡/ë³´ìƒ/ì¢…ë£Œ ì‹ í˜¸
        obs_list, per_agent_results, per_agent_infos = [], [], []
        for agent in self.agents:
            o = self._get_obs(agent, now_t, all_poses)
            r, done_i = self._compute_reward(agent, all_poses) 
            
            obs_list.append(o)
            per_agent_results.append((float(r), bool(done_i)))
            per_agent_infos.append({"reward": float(r)})

        team_reward, done_all, final_team_info = self._team_reward_and_done(per_agent_results, mission_accomplished)
        
        n = len(self.agents)
        rewards_list = [team_reward] * n
        dones_list = [done_all] * n
        infos_list = []
        for i in range(n):
            info_i = per_agent_infos[i].copy()
            info_i.update(final_team_info)
            infos_list.append(info_i)

        # âœ… ê°€ë””ì–¸(ë³´í˜¸) ë¡œì§
        leader_pos   = self._get_pose_xyz("Drone1")
        obstacle_pos = self._get_pose_xyz(self.dynamic_name)


        if self.leader_stop:
            print("ğŸ’¥[ë¦¬ë” í”¼ê²© ê°ì§€] leader_stop=True â†’ ì—í”¼ì†Œë“œ ì¢…ë£Œ")

            # ê´€ì¸¡ í¬ê¸°ë¥¼ ë¯¸ë¦¬ ê°€ì ¸ì˜¤ê¸°
            obs_dim = self.observation_spaces[self.agents[0]].shape[0]
            zero_obs = np.zeros(obs_dim, dtype=np.float32)

            obs_list = [zero_obs.copy() for _ in self.agents]
            rewards_list = [-150.0] * len(self.agents)
            dones_list = [True] * len(self.agents)
            infos_list = [{"event": "leader_stop_triggered"} for _ in self.agents]
            return obs_list, rewards_list, dones_list, infos_list

        
        # íŒ”ë¡œì›Œ(ê°€ë””ì–¸)ê°€ ë§‰ì€ ê²½ìš°
        for agent in self.agents:
            agent_pos = self._get_pose_xyz(agent)
            if np.linalg.norm(agent_pos[:2] - obstacle_pos[:2]) < 0.5:
                print(f"ğŸ›¡ï¸[ê°€ë””ì–¸ ì°¨í ì„±ê³µ] {agent} â†” DynamicObstacle (+3)")
                # ì„±ê³µ ë³´ë„ˆìŠ¤ +500ì  ë¶€ì—¬
                rewards_list = [500.0] * len(self.agents) 
                # ì¦‰ì‹œ ì—í”¼ì†Œë“œ ì¢…ë£Œ
                dones_list = [True] * len(self.agents)  
                infos_list = [{"event": "mission_success_guardian_block", "blocker": agent} for _ in self.agents]
                return obs_list, rewards_list, dones_list, infos_list
        
        return obs_list, rewards_list, dones_list, infos_list
    
