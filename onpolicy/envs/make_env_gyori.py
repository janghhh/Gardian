# from MARL_test import ParallelEnv
import gym
import numpy as np
import airsim
import math
import time
import random
from sklearn.cluster import DBSCAN

# import open3d as o3d
# from sklearn.datasets import

class AirSimMultiDroneEnv:
    metadata = {"render_modes": []}

    def __init__(
        self,
        ip_address="127.0.0.1",                 # ê¸°ë³¸ê°’
        follower_names=("Follower0","Follower1","Follower2"),
        lidar_name="LidarSensor",               # ë¼ì´ë‹¤ ê³µí†µëª… (ì‹¤ì œ ì„¼ì„œëŠ” f"{agent}_{lidar_name}")
        min_samples=5,
        step_length=1.0,
        fixed_z=-10.0,
        leader_step_length=0.3,                    # ìœ ì¸ê¸° ì†ë„(m/s) íŒŒë¼ë¯¸í„°í™”
        optimal_distance=10.0,                  # ì¶”ì¢… ìµœì  ê±°ë¦¬(ì‹œê°í™”ìš© ë§)
        far_cutoff=60.0,                        # ì´íƒˆ ì¢…ë£Œ ê±°ë¦¬(ì‹œê°í™”ìš© ë§)
        too_close=1.0,                          # ìœ ì¸ê¸°ì™€ ìµœì†Œ ê±°ë¦¬
        dt=0.05,                                # ë‚´ë¶€ ì‹œë®¬ë ˆì´ì…˜ íƒ€ì„ìŠ¤í…(ì´ˆ)
        do_visualize=True                       # ì›/í¬ì¸íŠ¸ ì‹œê°í™” on/off
    ):
        super().__init__()
        self.possible_agents = list(follower_names)
        self.agents = self.possible_agents[:]

        # ë¼ì´ë‹¤ / DBSCAN
        self.lidar_name = lidar_name
        self.min_samples = int(min_samples)
        self.eps = 0.3
        self.min_pts = 5

        # ê´€ì¸¡ê³µê°„(ë™ì  ê°ì²´ K-NN)
        self.K_nearest = 4                  # K-ìµœê·¼ì ‘ ë™ì  ê°ì²´ ê°œìˆ˜
        self.match_dist_max = 2.0           # í”„ë ˆì„ ê°„ í´ëŸ¬ìŠ¤í„° ë§¤ì¹­ í—ˆìš© ê±°ë¦¬[m]
        self._cluster_tracks = {a: {} for a in self.possible_agents}  # agentë³„ íŠ¸ë™ ì‚¬ì „
        self._next_cluster_id = {a: 0 for a in self.possible_agents}  # agentë³„ ID ì¦ê°€ê¸°

        # ì—ì´ì „íŠ¸/ë¦¬ë” ì†ë„ ì‚°ì¶œìš© ë²„í¼
        self._last_pose = {}     # {"name": np.array([x,y,z])}
        self._last_time = {}     # {"name": t_float}

        # ì†ë„/ì•¡ì…˜ ë²„í¼
        self.vmax_self = 10.0             # ìê¸° ì†ë„ ìƒí•œ(m/s) (í•™ìŠµ ì•ˆì •ìš©)
        self.vmax_cluster = 15.0
        self._timestep = 0

        # â˜… KeyError ë°©ì§€: ì•¡ì…˜ ë²„í¼ë¥¼ ì—ì´ì „íŠ¸ë³„ë¡œ ì´ˆê¸°í™”
        self._last_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self._current_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self.success_steps = {a: 0 for a in self.possible_agents}

        # ì´ë™ ëª¨ë“œ
        self.use_teleport = True  # Trueë©´ ìœ„ì¹˜ ë³´ì •(í…”ë ˆí¬íŠ¸) ê¸°ë°˜ ì´ë™

        # í´ë¼ì´ì–¸íŠ¸
        self.client = airsim.MultirotorClient(ip=ip_address)
        self.client.confirmConnection()

        # í•˜ì´í¼íŒŒë¼ë¯¸í„°/í™˜ê²½ íŒŒë¼ë¯¸í„°
        self.step_length = float(step_length)
        self.fixed_z = float(fixed_z)
        self.dt = float(dt)
        self.do_visualize = bool(do_visualize)

        self.leader_step_length = float(leader_step_length)
        self.optimal_distance = float(optimal_distance)
        self.far_cutoff = float(far_cutoff)
        self.too_close = float(too_close)
        self.follower_names = list(follower_names)

        self._first_setup = True

        # ===== obs / act / share_obs spaces =====
        # obs_dim = [self_vel(3) + rel_leader(3) + K * (rel_pos(3)+rel_vel(3))]
        obs_dim = 3 + 3 + self.K_nearest * (3 + 3)   # = 30
        act_dim = 2
        share_obs_dim = obs_dim * len(self.possible_agents)

        low_self = [-20.0, -20.0, -20.0]             # ì†ë„/ìƒëŒ€ìœ„ì¹˜ ëŒ€ëµì  í´ë¦½
        high_self = [ 20.0,  20.0,  20.0]
        low_rel = [-200.0, -200.0, -200.0]
        high_rel = [ 200.0,  200.0,  200.0]
        low_kn = [-200.0]*3 + [-20.0]*3
        high_kn = [ 200.0]*3 + [ 20.0]*3
        per_agent_low  = low_self + low_rel + (low_kn * self.K_nearest)
        per_agent_high = high_self + high_rel + (high_kn * self.K_nearest)

        self.observation_spaces = {
            agent: gym.spaces.Box(
                low=np.array(per_agent_low,  dtype=np.float32),
                high=np.array(per_agent_high, dtype=np.float32),
                shape=(obs_dim,), dtype=np.float32
            ) for agent in self.possible_agents
        }

        self.action_spaces = {
            agent: gym.spaces.Box(low=-1.0, high=1.0, shape=(act_dim,), dtype=np.float32)
            for agent in self.possible_agents
        }

        self.share_observation_spaces = gym.spaces.Box(
            low=np.array(per_agent_low * len(self.possible_agents), dtype=np.float32),
            high=np.array(per_agent_high * len(self.possible_agents), dtype=np.float32),
            shape=(share_obs_dim,), dtype=np.float32
        )

        self.current_waypoint_idx = 0
        self._setup_flight()
        self._generate_leader_waypoints()
        self._last_visualize_t = time.time()

    # ======================================================================
    # ë¼ì´ë‹¤ ë°ì´í„° â†’ DBSCAN â†’ íŠ¸ë™/ì†ë„ ì¶”ì •
    # ======================================================================
    def _lidar_sensor_name(self, agent: str) -> str:
        # ì‹¤ì œ AirSim ì„¤ì •: ê° ë“œë¡ ì— "Follower0_LidarSensor" ì‹ìœ¼ë¡œ ë¶™ì–´ ìˆë‹¤ê³  ê°€ì •
        return f"{agent}_{self.lidar_name}"

    def _LidarPointsWorld(self, agent, data_frame="VehicleInertialFrame"):
        ld = self.client.getLidarData(lidar_name=self._lidar_sensor_name(agent), vehicle_name=agent)
        arr = np.array(ld.point_cloud, dtype=np.float32)
        if arr.size == 0:
            return np.empty((0, 3), dtype=np.float32)
        pts = arr.reshape(-1, 3)
        return pts

    def _ClusterDbscanWorld(self, agent):
        pts_w = self._LidarPointsWorld(agent, data_frame="VehicleInertialFrame")
        if pts_w.shape[0] == 0:
            return []
        db = DBSCAN(eps=self.eps, min_samples=self.min_samples).fit(pts_w)
        labels = db.labels_
        clusters = []
        for cid in np.unique(labels):
            if cid == -1:
                continue
            idx = (labels == cid)
            cpts = pts_w[idx]
            centroid = cpts.mean(axis=0)
            clusters.append({"centroid": centroid, "count": int(idx.sum())})
        return clusters

    def _update_clusters_and_tracks(self, agent, now_t):
        tracks = self._cluster_tracks[agent]
        clusters = self._ClusterDbscanWorld(agent)

        cur_centroids = [c["centroid"] for c in clusters]
        cur_used = [False] * len(cur_centroids)

        # ê¸°ì¡´ íŠ¸ë™ ì—…ë°ì´íŠ¸/ì‚­ì œ
        for tid, st in list(tracks.items()):
            best_j, best_d = -1, 1e9
            for j, cen in enumerate(cur_centroids):
                if cur_used[j]:
                    continue
                d = np.linalg.norm(cen - st["centroid"])
                if d < best_d:
                    best_d, best_j = d, j

            if best_j >= 0 and best_d <= self.match_dist_max:
                dt = max(1e-6, now_t - st["last_t"])
                new_c = cur_centroids[best_j]
                vel = (new_c - st["centroid"]) / dt
                # í´ë¨í”„ + EMA
                vel = np.clip(vel, -self.vmax_cluster, self.vmax_cluster)
                prev = st.get("vel", np.zeros(3, np.float32))
                vel = 0.6 * prev + 0.4 * vel
                tracks[tid] = {"centroid": new_c, "vel": vel, "last_t": now_t}
                cur_used[best_j] = True
            else:
                if now_t - st["last_t"] > 1.0:
                    del tracks[tid]

        # ë§¤ì¹­ ì•ˆ ëœ í´ëŸ¬ìŠ¤í„°ëŠ” ì‹ ê·œ íŠ¸ë™ ìƒì„±
        for j, cen in enumerate(cur_centroids):
            if not cur_used[j]:
                tid = self._next_cluster_id[agent]
                self._next_cluster_id[agent] += 1
                tracks[tid] = {"centroid": cen, "vel": np.zeros(3, np.float32), "last_t": now_t}

    # ======================================================================
    # í¬ì¦ˆ/ì†ë„
    # ======================================================================
    def _get_pose_xyz(self, name):
        pose = self.client.simGetVehiclePose(vehicle_name=name).position
        return np.array([pose.x_val, pose.y_val, pose.z_val], dtype=np.float32)

    def _get_self_velocity(self, name, now_t, current_pos):
        """
        [ìµœì í™”ë¨] _get_pose_xyz() API í˜¸ì¶œì„ ì œê±°í•˜ê³ ,
        ë¯¸ë¦¬ ê³„ì‚°ëœ current_posë¥¼ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
        """
        if self.use_teleport and name in self._last_action:
            # í…”ë ˆí¬íŠ¸ ëª¨ë“œ (ê¸°ì¡´ê³¼ ë™ì¼, API í˜¸ì¶œ ì—†ìŒ)
            a = self._last_action[name] 
            vx = float(a[0]) * float(self.step_length) / self.dt
            vy = float(a[1]) * float(self.step_length) / self.dt
            vz = 0.0
            v = np.array([vx, vy, vz], dtype=np.float32)
        else:
            # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ì¸ìë¡œ ë°›ì€ 'current_pos' ì‚¬ìš©
            pos = current_pos 
            v = np.zeros(3, np.float32)
            if name in self._last_pose:
                dt = max(1e-6, now_t - self._last_time.get(name, now_t))
                v = (pos - self._last_pose[name]) / dt
            self._last_pose[name] = pos
            self._last_time[name] = now_t

        # í•™ìŠµ ì•ˆì •í™”ë¥¼ ìœ„í•œ í´ë¨í”„ & EMA (ê¸°ì¡´ê³¼ ë™ì¼)
        v = np.clip(v, -self.vmax_self, self.vmax_self)
        prev = getattr(self, "_vel_ema_" + name, v)
        v_ema = 0.7 * prev + 0.3 * v
        setattr(self, "_vel_ema_" + name, v_ema)
        return v_ema

    def _get_knn_features(self, agent, K, now_t, all_poses):
        """
        [ìµœì í™”ë¨] _get_pose_xyz() API í˜¸ì¶œì„ ì œê±°í•˜ê³ ,
        ë¯¸ë¦¬ ê³„ì‚°ëœ all_poses ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        
        # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ
        pos_a = all_poses[agent]
        
        # (ìˆ˜ì •) ìµœì í™”ëœ ì†ë„ í•¨ìˆ˜ í˜¸ì¶œ
        vel_a = self._get_self_velocity(agent, now_t, pos_a)

        feats = []
        cand = []
        # (ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
        for _, tr in self._cluster_tracks[agent].items():
            rel_pos = tr["centroid"] - pos_a
            rel_vel = tr["vel"] - vel_a
            dist = np.linalg.norm(rel_pos)
            cand.append((dist, rel_pos, rel_vel))
        cand.sort(key=lambda x: x[0])

        for i in range(K):
            if i < len(cand):
                _, rp, rv = cand[i]
                feats.extend([rp[0], rp[1], rp[2], rv[0], rv[1], rv[2]])
            else:
                feats.extend([0.0, 0.0, 0.0, 0.0, 0.0, 0.0])  # íŒ¨ë”©
        return np.array(feats, dtype=np.float32)

    # ======================================================================
    # Spaces (PettingZoo-style getters)
    # ======================================================================
    @property
    def observation_space(self):
        return [self.observation_spaces[a] for a in self.possible_agents]

    @property
    def action_space(self):
        return [self.action_spaces[a] for a in self.possible_agents]

    @property
    def share_observation_space(self):
        return [self.share_observation_spaces for _ in self.possible_agents]

    def seed(self, seed):
        random.seed(seed)
        np.random.seed(seed)

    # ======================================================================
    # ì´ˆê¸°í™”/ì´ë¥™/ì‹œì‘ ë°°ì¹˜
    # ======================================================================
    def _setup_flight(self):
        if self._first_setup:
            self.client.reset()
            # ë¦¬ë” + íŒ”ë¡œì›Œ API ì œì–´ / ì•”
            self.client.enableApiControl(True, vehicle_name="Drone1")
            self.client.armDisarm(True, vehicle_name="Drone1")
            for agent in self.possible_agents:
                self.client.enableApiControl(True, vehicle_name=agent)
                self.client.armDisarm(True, vehicle_name=agent)

            futs = [self.client.takeoffAsync(vehicle_name="Drone1")]
            futs += [self.client.takeoffAsync(vehicle_name=a) for a in self.possible_agents]
            for f in futs:
                f.join()
            time.sleep(1.0)
            self._teleport_to_start()
            self._first_setup = False

    def _teleport_to_start(self):
        # settings.jsonì— ë§ì¶˜ ì‹œì‘ ì¢Œí‘œ (X, Y, Z)
        start_cfg = {
            "Drone1":   (5.0,  2.5, float(self.fixed_z)),
            "Follower0":(0.0,  0.0, float(self.fixed_z)),
            "Follower1":(0.0,  2.5, float(self.fixed_z)),
            "Follower2":(0.0,  5.0, float(self.fixed_z)),
        }

        # API ì œì–´ ë³´ì¥
        self.client.enableApiControl(True, vehicle_name="Drone1")
        for agent in self.possible_agents:
            self.client.enableApiControl(True, vehicle_name=agent)

        # í…”ë ˆí¬íŠ¸
        for name, (x, y, z) in start_cfg.items():
            px, py, pz = float(x), float(y), float(z)
            self.client.simSetVehiclePose(
                airsim.Pose(
                    airsim.Vector3r(px, py, pz),
                    airsim.Quaternionr(0.0, 0.0, 0.0, 1.0)
                ),
                ignore_collision=True,
                vehicle_name=name
            )
        time.sleep(0.05)

    # ======================================================================
    # ìœ ì¸ê¸° ê²½ë¡œ/ì´ë™/ì‹œê°í™”
    # ======================================================================
    def _generate_leader_waypoints(self):
        leader_start_pos = np.array([5.0, 2.5, self.fixed_z])

        # ì‹œì‘ì ìœ¼ë¡œë¶€í„° 50~70m ë–¨ì–´ì§„ ê³³ì— ë¬´ì‘ìœ„ ëª©ì ì§€ ì„¤ì •
        distance = random.uniform(50.0, 70.0)
        angle = random.uniform(0, 2 * np.pi)

        final_destination = leader_start_pos + np.array([
            distance * np.cos(angle),
            distance * np.sin(angle),
            0.0
        ])

        self.leader_waypoints = [final_destination]
        self.current_waypoint_idx = 0

        # ëª©ì ì§€ ì‹œê°í™”ìš© ì˜¤ë¸Œì íŠ¸ ì´ë™(ìˆì„ ë•Œë§Œ)
        object_name = "target1v1_5"
        try:
            flag_position = airsim.Vector3r(
                float(final_destination[0]),
                float(final_destination[1]),
                float(self.fixed_z + 8.0)
            )
            flag_orientation = airsim.to_quaternion(0, 80.1, 0)
            flag_pose = airsim.Pose(flag_position, flag_orientation)
            self.client.simSetObjectPose(object_name, flag_pose)
        except Exception as e:
            print(f"'{object_name}' ê°ì²´ ì´ë™ ì‹¤íŒ¨(ì–¸ë¦¬ì–¼ì— ì—†ì„ ìˆ˜ ìˆìŒ): {e}")

    def _update_leader_movement(self):
        """
        ìœ ì¸ê¸°ë¥¼ ëª©ì ì§€ë¡œ ì´ë™ì‹œí‚¤ê³ , ë„ì°© ì‹œ ì„±ê³µ ì—¬ë¶€ ë°˜í™˜.
        Returns:
            mission_accomplished (bool)
        """
        if not self.leader_waypoints:
            self._generate_leader_waypoints()

        target = self.leader_waypoints[0]

        pose = self.client.simGetVehiclePose(vehicle_name="Drone1")
        cur = np.array([pose.position.x_val, pose.position.y_val, pose.position.z_val])

        # ëª©ì ì§€ ë„ì°© íŒì • (XY ê±°ë¦¬ ê¸°ì¤€)
        dist_to_target = np.linalg.norm(target[:2] - cur[:2])
        if dist_to_target < 3.0:
            return True  # ë¯¸ì…˜ ì„±ê³µ!

        # ëª©ì ì§€ë¥¼ í–¥í•´ ì´ë™
        dir_vec = target - cur
        dist = np.linalg.norm(dir_vec[:2])
        if dist > 1e-6:
            dir_unit = dir_vec / (dist + 1e-9)
            move = dir_unit * self.leader_step_length / 2
            new_pos = cur + move
            self.client.simSetVehiclePose(
                airsim.Pose(
                    airsim.Vector3r(new_pos[0], new_pos[1], self.fixed_z),
                    airsim.Quaternionr()
                ),
                ignore_collision=True,
                vehicle_name="Drone1"
            )
        

        # ì‹œê°í™”
        if self.do_visualize:
            now = time.time()
            if (now - self._last_visualize_t) >= 0.5:
                self.client.simFlushPersistentMarkers()
                self._visualize_circles()
                self._last_visualize_t = now

        return False


    def _visualize_circles(self):
        try:
            # 1. ë¦¬ë” ìœ„ì¹˜ ê°€ì ¸ì˜¤ê¸°: simGetObjectPose ì‚¬ìš©ìœ¼ë¡œ ìˆ˜ì •
            # 'Drone1'ì´ ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ì˜ ê°ì²´ ì´ë¦„ì´ë¼ê³  ê°€ì •
            leader_pose = self.client.simGetObjectPose(object_name="Drone1")
            if leader_pose is None:
                # ê°ì²´ í¬ì¦ˆë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ëŠ” ê²½ìš° ì‹œê°í™” ê±´ë„ˆë›°ê¸°
                return 
            
            leader_pos = leader_pose.position
            
            # ì¤‘ì‹¬ ì¢Œí‘œ (Numpy ë°°ì—´ë¡œ ë³€í™˜)
            center = np.array([leader_pos.x_val, leader_pos.y_val, leader_pos.z_val], dtype=float)

            def ring_points(radius, n=36):
                """ì£¼ì–´ì§„ ë°˜ì§€ë¦„ê³¼ ì¤‘ì‹¬ì„ ì‚¬ìš©í•˜ì—¬ ë§ì˜ ì ë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
                pts = []
                for i in range(n + 1):
                    ang = (i / n) * 2 * np.pi
                    x = center[0] + radius * np.cos(ang)
                    y = center[1] + radius * np.sin(ang)
                    z = center[2] # ë¦¬ë”ì˜ Z ìœ„ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    pts.append(airsim.Vector3r(x, y, z))
                return pts

            # ì‹œê°í™” ì„¤ì •
            line_thickness = 15.0
            duration = 0.1 # ê·¸ë¦¬ëŠ” ì§€ì† ì‹œê°„
            color = [1, 1, 0, 0.8] 

            # 2. 5m ë§ ê·¸ë¦¬ê¸° (ë™ì¼ ìƒ‰ìƒ)
            self.client.simPlotLineStrip(ring_points(5.0), color, line_thickness, duration, True)
            
            # 3. 10m ë§ ê·¸ë¦¬ê¸° (ë™ì¼ ìƒ‰ìƒ)
            self.client.simPlotLineStrip(ring_points(10.0), color, line_thickness, duration, True)
            
        except Exception as e:
            # ì‹œê°í™” ì‹¤íŒ¨ ë¬´ì‹œ (ë””ë²„ê¹…ì„ ìœ„í•´ ì˜ˆì™¸ë¥¼ ì¶œë ¥í•  ìˆ˜ë„ ìˆìŒ)
            # print(f"Visualization failed: {e}")
            pass

    # ======================================================================
    # ê´€ì¸¡/ì•¡ì…˜/ë³´ìƒ
    # ======================================================================
    def _get_obs(self, agent, now_t, all_poses):
        now_t = self._timestep * self.dt
        """
        [ìµœì í™”ë¨] API í˜¸ì¶œ ì—†ì´ all_poses ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•´ ê´€ì¸¡ê°’ì„ ìƒì„±í•©ë‹ˆë‹¤.
        """
    
        # 1) ìì‹  ì†ë„
        # (ìˆ˜ì •) _get_pose_xyzë¥¼ í˜¸ì¶œí•˜ì§€ ì•Šë„ë¡, í˜„ì¬ ìœ„ì¹˜(all_poses[agent])ë¥¼ ì¸ìë¡œ ì „ë‹¬
        self_vel = self._get_self_velocity(agent, now_t, all_poses[agent])

        # 2) ìœ ì¸ê¸° ìƒëŒ€ ìœ„ì¹˜ (ë¦¬ë”-ì—ì´ì „íŠ¸)
        # (ìˆ˜ì •) API í˜¸ì¶œ ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ ì¡°íšŒ
        leader_pos = all_poses["Drone1"]
        agent_pos  = all_poses[agent]
        rel_la = (leader_pos - agent_pos).astype(np.float32)

        # 3) K-ìµœê·¼ì ‘ ë™ì  ê°ì²´: ìƒëŒ€ ìœ„ì¹˜ + ìƒëŒ€ ì†ë„
        # (ìˆ˜ì •) _get_knn_featuresê°€ ë”•ì…”ë„ˆë¦¬ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
        kn_feats = self._get_knn_features(agent, self.K_nearest, now_t, all_poses)

        obs = np.concatenate([self_vel, rel_la, kn_feats], axis=0).astype(np.float32)
        return obs

    def _do_action(self, agent, action):
        a = np.clip(np.asarray(action, dtype=np.float32), -1.0, 1.0)
        self._last_action[agent] = a.copy()
        self._current_action[agent] = a.copy()  # â˜… í˜„ì¬ ì•¡ì…˜ ê¸°ë¡ (KeyError ë°©ì§€)

        pose = self.client.simGetVehiclePose(agent)
        x, y, z = pose.position.x_val, pose.position.y_val, self.fixed_z

        dx = float(a[0]) * float(self.step_length)
        dy = float(a[1]) * float(self.step_length)

        nx = float(x) + dx
        ny = float(y) + dy
        nz = float(z)

        new_pos = airsim.Vector3r(nx, ny, nz)
        new_pose = airsim.Pose(new_pos, airsim.Quaternionr(0.0, 0.0, 0.0, 1.0))
        self.client.simSetVehiclePose(new_pose, False, vehicle_name=agent)
  

    def _compute_reward(self, agent, all_poses):
        # === ê±°ë¦¬ ë° ìœ„ì¹˜ ê³„ì‚° ===
        leader_pos = all_poses["Drone1"]
        agent_pos = all_poses[agent]
        
        # ë¦¬ë”ì™€ì˜ ê±°ë¦¬ (3D ë²¡í„° ë…¸ë¦„ ì‚¬ìš© ê°€ì •)
        dist = np.linalg.norm(leader_pos - agent_pos) 
        #-------------------------[ìˆ˜ì •í•œ ë¶€ë¶„]-------------------------------
        repulsion_penalty = 0.0
        MIN_SAFE_DISTANCE = 3.0  # ì•ˆì „ ê±°ë¦¬ (ì˜ˆ: 3m)
        
        for other in self.agents:
            if other == agent:
                continue
            
            other_pos = all_poses[other]
            dist_agents = np.linalg.norm([agent_pos[0] - other_pos[0],
                                        agent_pos[1] - other_pos[1]])
            
            # (1) í•˜ë“œ ì¶©ëŒ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            if dist_agents < 0.5:
                print(f"ğŸ’¥ {agent}ì™€ {other} ì¶©ëŒ!")
                return -150.0, True  # ì¦‰ì‹œ ì¢…ë£Œ

            # (2) ì•ˆì „ ê±°ë¦¬ ì¹¨ë²” ì‹œ ì—°ì†ì ì¸ í˜ë„í‹°
            if dist_agents < MIN_SAFE_DISTANCE:
                # ê±°ë¦¬ê°€ 0.5mì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ í˜ë„í‹°ê°€ ê¸°í•˜ê¸‰ìˆ˜ì ìœ¼ë¡œ ì¦ê°€
                # 3mì¼ ë•Œ: -0.1 * (3.0 - 0.5) / (3.0 - 0.5) = -0.1
                # 0.5m ì§ì „ì¼ ë•Œ: ë§¤ìš° í° ìŒìˆ˜
                repulsion_penalty -= 0.1 / (dist_agents - 0.49) # 0.5mì—ì„œ ë°œì‚°í•˜ë„ë¡ (0.49ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°)
        #-------------------------[ì—¬ê¸°ê¹Œì§€ ìˆ˜ì •]-------------------------------
        
        # === (2) ë¦¬ë”ì™€ì˜ ê±°ë¦¬ ì´íƒˆ/ì¶©ëŒ ì²˜ë¦¬ ===
        if dist < 0.5 or dist > 60.0:
            print("ğŸ’¤ë¦¬ë”ì™€ì˜ ê±°ë¦¬ ë„ˆë¬´ ë©€ê±°ë‚˜ ê°€ê¹Œì›€!")
            return -150.0, True  # ë¦¬ë”ì™€ì˜ ê±°ë¦¬ ì´íƒˆ/ì¶©ëŒ ì‹œ ì¦‰ì‹œ ì¢…ë£Œ

        # === (3) ê±°ë¦¬ ë³´ìƒ ê³„ì‚° (ë¹„ì¢…ë£Œ êµ¬ê°„: 0.5m < dist <= 60.0m) ===
        
        if 5.0 <= dist <= 10.0:
            # ìµœì  ê±°ë¦¬ êµ¬ê°„: ìµœê³  ë³´ìƒ (ê³ ì • +3.0)
            dist_reward = 3.0
        elif 0.5 < dist < 5.0:
            # 0.5m~5m: 5më¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, 0.5mì—ì„œ -150, 5mì—ì„œ +3ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ê°€ìš°ì‹œì•ˆ
            dist_reward = -150.0 + (153.0) * math.exp(-((dist - 5.0)**2) / (2 * 1.5**2))
            dist_reward = np.clip(dist_reward, -150.0, 3.0)
        elif 10.0 < dist <= 60.0:
            # 10m~60m: 10më¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, 60mì—ì„œ -150, 10mì—ì„œ +3ìœ¼ë¡œ ìˆ˜ë ´í•˜ëŠ” ê°€ìš°ì‹œì•ˆ
            dist_reward = -150.0 + (153.0) * math.exp(-((dist - 10.0)**2) / (2 * 15.0**2))
            dist_reward = np.clip(dist_reward, -150.0, 3.0)
        else:
            # ì´ else ë¬¸ì€ 0.5m < dist <= 60.0m ì¡°ê±´ ë‚´ì—ì„œ ë¶ˆê°€ëŠ¥í•¨ (ë…¼ë¦¬ì  ë³´ìˆ˜ì„±)
            dist_reward = -150.0 

        # === (4) ë¶€ë“œëŸ¬ìš´ ì´ë™ í˜ë„í‹° (Smoothness Penalty) ===
        prev_action = self._last_action.get(agent, np.zeros(2))
        curr_action = self._current_action.get(agent, np.zeros(2))
        smooth_penalty = -0.1 * np.linalg.norm(curr_action - prev_action)

        # === (5) ì„±ê³µ ìŠ¤í… ì‹œê°„ ë³´ë„ˆìŠ¤ ===
        # ì„±ê³µ ìŠ¤í… ì¡°ê±´ ìˆ˜ì •: 5.0m <= dist <= 10.0më¡œ ê²½ê³„ í¬í•¨
        is_success_step = 1 if 5.0 <= dist <= 10.0 else 0
        self.success_steps[agent] += is_success_step
        time_bonus = 0.001 * self.success_steps[agent]

        # === (6) ìµœì¢… í•©ì‚° ===
        final_reward = dist_reward + smooth_penalty + time_bonus
        
        # ë¹„ì¢…ë£Œ ìŠ¤í…ì´ë¯€ë¡œ done=False ë°˜í™˜
        return float(final_reward), False
    

    # íŒ€ ë³´ìƒ ì§‘ê³„(í‰ê· ) + ì•ˆì „ ê²Œì´íŠ¸
    def _team_reward_and_done(self, per_agent_results, mission_accomplished=False):
        # ì•ˆì „ ê²Œì´íŠ¸: í•œ ëª…ì´ë¼ë„ ì¢…ë£Œì´ë©´ ì¦‰ì‹œ ì‹¤íŒ¨
        any_fail = any(done_i for (_, done_i) in per_agent_results)
        if any_fail:
            print("ğŸ›‘ì—ì´ì „íŠ¸ í•˜ë‚˜ ì¢…ë£Œë¨. ë¯¸ì…˜ ì‹¤íŒ¨ğŸ›‘")
            return -200.0, True, {"final_status": "FAIL_CRASH"}

        # ë¯¸ì…˜ ì„±ê³µ: ìœ ì¸ê¸°ê°€ ëª©ì ì§€ ë„ì°©
        if mission_accomplished:
            tracking_rewards = [r_i for (r_i, _) in per_agent_results]
            final_reward = float(np.mean(tracking_rewards)) + 500.0
            print("â­ï¸ë¯¸ì…˜ ì„±ê³µâ­ï¸")
            return final_reward, True, {"final_status": "SUCCESS"}

        # ë¯¸ì…˜ ì§„í–‰ ì¤‘: ì¶”ì¢… ë³´ìƒì˜ í‰ê· 
        tracking_rewards = [r_i for (r_i, _) in per_agent_results]
        return float(np.mean(tracking_rewards)), False, {}

    # ======================================================================
    # PettingZoo API-ish
    # ======================================================================   
    def reset(self, seed=None, options=None):
        self.agents = self.possible_agents[:]
        self._setup_flight()
        self._generate_leader_waypoints()
        self.current_waypoint_idx = 0
        self._teleport_to_start() # <- ë“œë¡  ìœ„ì¹˜ê°€ ì—¬ê¸°ì„œ ì„¤ì •ë¨
        self.client.simFlushPersistentMarkers()

        # â˜… ì—í”¼ì†Œë“œ ì‹œì‘ ì‹œ ë²„í¼ ë¦¬ì…‹ (ê¸°ì¡´ ì½”ë“œ)
        self._timestep = 0
        self._last_pose.clear()
        self._last_time.clear()
        self._last_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self._current_action = {a: np.zeros(2, dtype=np.float32) for a in self.possible_agents}
        self.success_steps = {a: 0 for a in self.possible_agents}
        self._cluster_tracks = {a: {} for a in self.possible_agents}
        self._next_cluster_id = {a: 0 for a in self.possible_agents}

        # 'step' í•¨ìˆ˜ì—ì„œì²˜ëŸ¼ 'now_t'ì™€ 'all_poses'ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        now_t = self._timestep * self.dt  # (now_t = 0.0)
        
        all_poses = {}
        all_poses["Drone1"] = self._get_pose_xyz("Drone1") # ìœ ì¸ê¸°
        for agent in self.agents:
            all_poses[agent] = self._get_pose_xyz(agent) # ì—ì´ì „íŠ¸

        obs_list = [self._get_obs(a, now_t, all_poses) for a in self.agents]
        
        return obs_list

    def step(self, actions):
        self._timestep += 1
        now_t = self._timestep * self.dt

        # A) LiDAR ê¸°ë°˜ íŠ¸ë™ ê°±ì‹ 
        for agent in self.agents:
            if agent.startswith("Follower"):
                self._update_clusters_and_tracks(agent, now_t)

        # B) ì•¡ì…˜ ì ìš©
        for agent, act in zip(self.agents, actions):
            self._do_action(agent, act)

        # C) ë¦¬ë” ì´ë™/ì‹œê°í™”
        mission_accomplished = self._update_leader_movement()

        # â˜…â˜…â˜… [ìµœì í™”] ëª¨ë“  ìœ„ì¹˜ ì •ë³´ë¥¼ ì´ ì‹œì ì— "í•œ ë²ˆë§Œ" ê°€ì ¸ì˜´ â˜…â˜…â˜…
        all_poses = {}
        all_poses["Drone1"] = self._get_pose_xyz("Drone1") # ìœ ì¸ê¸°
        for agent in self.agents:
            all_poses[agent] = self._get_pose_xyz(agent) # ì—ì´ì „íŠ¸

        # D) ê´€ì¸¡/ë³´ìƒ/ì¢…ë£Œ ì‹ í˜¸
        obs_list, per_agent_results, per_agent_infos = [], [], []
        for agent in self.agents:
            # â˜… (ìˆ˜ì •) ìµœì í™”ëœ _get_obs í•¨ìˆ˜ í˜¸ì¶œ â˜…
            o = self._get_obs(agent, now_t, all_poses)
            
            # â˜… (ìˆ˜ì •) ìµœì í™”ëœ _compute_reward í•¨ìˆ˜ í˜¸ì¶œ â˜…
            r, done_i = self._compute_reward(agent, all_poses) 
            
            obs_list.append(o)
            per_agent_results.append((float(r), bool(done_i)))
            per_agent_infos.append({"reward": float(r)})

        # --- (ì´í•˜ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ---
        team_reward, done_all, final_team_info = self._team_reward_and_done(per_agent_results, mission_accomplished)
        
        # ... (ì´í•˜ ë™ì¼) ...
        n = len(self.agents)
        rewards_list = [team_reward] * n
        dones_list = [done_all] * n
        infos_list = []
        for i in range(n):
            info_i = per_agent_infos[i].copy()
            info_i.update(final_team_info)
            infos_list.append(info_i)

        return obs_list, rewards_list, dones_list, infos_list
